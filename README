This project is a student project related to the study of Machine Learning. Specifically, this project tries to build the fastest implementation of Parametrized Rocchio Classifier (PRC) that is described in this paper: http://disi.unitn.it/moschitti/Projects/ECIR03.pdf (Alessandro Moschitti. 2003. A study on optimal parameter tuning for Rocchio text classifier. In Proceedings of the 25th European conference on IR research (ECIR'03), Fabrizio Sebastiani (Ed.). Springer-Verlag, Berlin, Heidelberg, 420-435.) More information on Rocchio can be obtained from Prof. Moschitti's teaching website: http://disi.unitn.it/moschitti/teaching.html, specifically the slide on Automated Text Categorization.

See INSTALL to know how to build the codebase and use it.
See doc/ for the documentations and further information.
See HACKING for some suggested ways to debug and develop the codebase further.
See COPYING for the LICENSE of the codebase.
See below for the experiment result.

Below are some experiment results that I obtain using the following setup:
1. A*Note Laptop (http://0x657573.wordpress.com/2010/12/12/finding-another-free-software-compatible-x86-laptop-anote/)
* Intel Pentium Dual Core T3400 (1MB L2 cache, 2.16 GHz, 667 MHz FSB)
* 2GB DDR2 RAM
* Intel 965GM chipset, X3100GMA

2. Software
* GNU/Linux Ubuntu 10.10 operating system
* GNU C Library Ubuntu EGLIBC 2.12.1-0ubuntu10.2
* GCC 4.4.5

3. Compilation
* Using -O3 and -DBUFFER_SIZE=4096

I measure the computation performance in terms of the processing time, the CPU usage and the ratio of the process's CPU seconds spent in user mode and in system mode (i.e., user/sys). While CPU usage can indicate how efficient a program does its calculation, a low (i.e., less than or equal to 1) user/sys ratio can indicate performance bottle-neck like doing output within a loop, frequent swapping to disk, frequent page fault, frequent user space to kernel space switching, which is rather expensive, and the like. On the other hand, having user/sys ratio nearing infinity does not always indicate a good performance because an intensive computation in the user space may hide the existence of the aforementioned performance bottle-necks (see doc/output_kills/README).

I observe that performance really suffers when doing output but not when doing input. Beside this, I also observe that C file outputting facility (e.g., fprintf) has much better performance compared to that of C++ (e.g., doing `myfile << 0.2322;'). The details of the experiment that leads to this conclusion can be found in doc/output_kills/README.

Due to not checking the behavior of `xargs', I only discovered much later that processing unit w_to_vector did not receive all documents to be processed because there is a limit on the number of command line arguments that can be passed to a process. Specifically, only 3,613 weight vectors were stored in w_vectors.bin to be processed by processing unit rocchio because only 3,613 files are given by `xargs' as command line arguments. This problem can be prevented by forcing `xargs' to quit using `-x' if the number of command line arguments exceeds the limit.

Aside from this, even if `xargs' did not present that limitation, w_to_vector actually could not output all weight vectors of all documents. This is because of file size limit of the operating systems. Since each weight vector has 29,633 elements and the total number of unique documents in the training set is 9,598, the minimum size of file w_vectors.bin is 8 bytes x 29,633 x 9,598 = 2,275,340,272 bytes, which is more than 2 GiB. However, because the weight vectors are sparse vectors, an efficient data structure and computation can be devised. As advised by Prof. Moschitti, the elements of a weight vector can be put in a binary search tree.

Experiment results:
1. On Reuters21578-Apte-90Cat (http://disi.unitn.it/moschitti/corpora/Reuters21578-Apte-90Cat.tar.gz). The number of unique documents is 9,598 documents. Total number of unique features is 29,633 according to ROI dictionary in which ROI automatically filters out all single alphanumeric character (i.e., [a-z0-9]).

* The performance of reference of implementation (ROI) provided by Prof. Moschitti (the driver program is doc/ROI/roi_driver.sh):
** Step 1. Tokenization using my tokenizer because ROI does not provide the tokenizer takes 28.276s at CPU usage of 12.59% with user/sys ratio of 0.205.

** Step 2. TF generation
bin/TCF UNI -RCclusteringCategories
takes 5.579s at CPU usage of 87.62% with user/sys ratio of 17.238

** Step 3. Putting all training docs into splitClasses/
bin/TCF CCE -SP0 -SE1
takes 12.538s at CPU usage of 93.22% with user/sys ratio of 62.527

** Step 4. IDF_nf building
bin/TCF GCE -DF0
takes 0.250s at CPU usage of 97.57% with user/sys ratio of 29.500

** Step 5. Generating binary classifiers using P=1 without using any ES (estimation set) and doing classifications
bin/TCF DIC -GA0
takes 5.375s at CPU usage of 91.32% with user/sys ratio of 19.450

** Step 6. Put all training docs into classes/
bin/TCF CCE -SP100 -SE1
takes 9.082s at CPU usage of 95.22% with user/sys ratio of 14.555

** Step 7. Measuring performance
bin/TCF CLA -BP > BEP
takes 7.905s at CPU usage of 99.79% with user/sys ratio of 4.373
MacroAverage: Recall: 0.886381, Precision: 0.886376
MicroAverage: Recall: 0.836986, Precision: 0.837073, f1: 0.837030

** Total running time is 69.005s.

* My implementation
** Step 1. Tokenization and TF calculation takes 36.534s at CPU usage of 16.02% with user/sys ratio of 0.916.

Below are some further experiments of different approaches using Reuters21578-Apte-115Cat (http://disi.unitn.it/moschitti/corpora/Reuters21578-Apte-115Cat.tar.gz) on GNU/Linux Ubuntu 9.04 using GCC 4.3.3 and GNU C Library 2.9:
*** Without parallelism,
"$exec_dir"/tokenizer $cat/$file | "$exec_dir"/tf > "$result_dir"/$directory/$file.tf
results in:
real	1m33.018s
user	0m31.930s
sys	0m53.555s

*** With parallelism using `sed' as the tokenizer,
( sed -e 's%[] ,.;:?!<>()["'\''{}\r\n\t\v-]%\n%g' $cat/$file | $tf -o $result_dir/$directory/$file.tf) &
results in 40.681s at CPU usage of 100.00% with user/sys ratio of 0.620.

*** With parallelism,
( $exec_dir/tokenizer $cat/$file | $exec_dir/tf -o $result_dir/$directory/$file.tf) &
results in:
real	0m30.183s
user	0m16.641s
sys	0m33.690s

*** Using bash -c is slower as shown below.
bash -c $exec_dir'/tokenizer '$cat/$file' | '$exec_dir'/tf -o '$result_dir/$directory/$file.tf &
results in:
real	0m53.261s
user	0m37.258s
sys	0m52.531s

*** Combining tokenizer and tf into a single process results in 25% speed up.
( "$exec_dir"/tok_tf $cat/$file > "$result_dir"/$directory/$file.tf ) &
real	0m22.627s
user	0m11.625s
sys	0m22.585s

*** Without parallelism, tokenizer and tf as one process is still poor.
"$exec_dir"/tok_tf $cat/$file > "$result_dir"/$directory/$file.tf
real	1m10.243s
user	0m23.973s
sys	0m43.395s

*** To conclude, parallelism is the way to go and piping surely incurs overhead that is justified by modifiability reason (e.g., adding stop list processing unit is very easy when pipe is used).

** Step 2. IDF calculation and dictionary building takes 3.066s at CPU usage of 97.07% with user/sys ratio of 10.625.

** Step 3. Generation of w vectors for all documents takes 1.309s at CPU usage of 99.66% with user/sys ratio of 5.653 after harnessing sparse vector representation and taking file names to be processed from standard input or a file instead of passing the file names as a command-line argument.

Previously using Reuters21578-Apte-115Cat (http://disi.unitn.it/moschitti/corpora/Reuters21578-Apte-115Cat.tar.gz) on GNU/Linux Ubuntu 9.04 using GCC 4.3.3 and GNU C Library 2.9, without sparse vector representation and by passing the file names as a command-line argument, it took 149.705s at CPU usage of 35.80% with user/sys ratio of 1.738 and only 3,613 documents are processed due to the limitation of the number command line arguments that can be passed into a process as described above.

Below are some experiments of different approaches using Reuters21578-Apte-115Cat (http://disi.unitn.it/moschitti/corpora/Reuters21578-Apte-115Cat.tar.gz) on GNU/Linux Ubuntu 9.04 using GCC 4.3.3 and GNU C Library 2.9:
*** Using socket in which idf_dic processing unit acts as a server and several w_to_vector processing units act as clients in which each w_to_vector processing unit takes care of only one document (see https://github.com/eus/tc_rocchio/commit/24b7db191e82d6d3f694dd6828b9cd7af0061e80),
( $exec_dir/w_to_vector -D /tmp/tc_rocchio/idf_dic.socket -o $file.w $file ) &
results in:
real	3m21.748s
user	1m34.854s
sys	3m19.760s

*** If socket is removed and each w_to_vector processing unit loads IDF_DIC file directly, the IDF_DIC file load time is just too much as shown below.
real	9m45.863s
user	14m54.820s
sys	2m5.164s

*** Using only one w_to_vector processing unit to load IDF_DIC file once and process all TF documents serially takes 138.011s at CPU usage of 38.31% which is 32% speed up. But, I notice that this processing unit does not have a stable performance. Last time it was around 178s. After that, it was around 150s. Although previously I thought that this was because the processing unit processes the input files one-by-one resulting in the OS scheduler disadvantaging this processing unit, it is clear now that this is because the number of command line arguments are limited by xargs resulting in more documents in one case and less documents in the other case due to different length of the absolute path of file names as a result of putting the intermediate files in deeper subdirectories in the latter case.

** Step 4. Generation of PRCs (Parametrized Rocchio Classifiers) of all categories using P = 1 and and without using any ES takes 4.802s at CPU usage of 99.79% with user/sys ratio of 91.153. The classifier of any category is a binary classifer consisting of a W vector and a threshold.

Using Reuters21578-Apte-115Cat (http://disi.unitn.it/moschitti/corpora/Reuters21578-Apte-115Cat.tar.gz) on GNU/Linux Ubuntu 9.04 using GCC 4.3.3 and GNU C Library 2.9, calculating only the W vectors of all categories using a fixed value of P and without doing any threshold estimation takes 1.384s at CPU usage of 97.68% with user/sys ratio of 47.285 by using sparse vector representation. Previously without sparse vector representation, it was 4.732s at CPU usage of 97.22% but with a fatal logic error in which calculation of a profile vector is prematurely aborted by using `goto output' once an element in the vector is negative. Aside from that, only 3,613 weight vectors were processed due to an error in the processing unit w_to_vector.

** Step 5. Classifying the training set itself takes 6.829s at CPU usage of 99.81% with user/sys ratio of 141.000 and obtains:
[MacroAverage] Recall: 0.885104, Precision: 0.885104
[MicroAverage] Recall: 0.836899, Precision: 0.836899, f1: 0.836899

Previously using Reuters21578-Apte-115Cat (http://disi.unitn.it/moschitti/corpora/Reuters21578-Apte-115Cat.tar.gz) on GNU/Linux Ubuntu 9.04 using GCC 4.3.3 and GNU C Library 2.9, in the presence of logic error due to my misunderstanding of OVA, it was 6.816s at CPU usage of 96.00% with user/sys ratio of 76.904 by using sparse vector representation and taking file names to be processed from standard input or a file. Previously without sparse vector representation and by passing the file names as a command-line argument, it took 32.982s at CPU usage of 93.60% with user/sys ratio of 42.362 although only 3,613 weight vectors were considered. Previoulsy I thought that the slowness was due to either output operations or not harnessing sparse vectors. Now I can conclude that it is because of not harnessing sparse vectors.

** Step 6. Tokenization and TF calculation of the test set takes 12.207s at CPU usage of 17.36% with user/sys ratio of 1.387.

** Step 7. Test set w vectors generation takes 0.489s at CPU usage of 99.04% with user/sys ratio of 9.083.

** Step 8. OVA classification of the test set takes 2.235s at CPU usage of 97.88% with user/sys ratio of 272.500.

** Step 9. Measuring the performances of the classifiers takes 0.013s at CPU usage of 63.94% with user/sys ratio of 1.000.

** Total running time is 52.54s for the training phase (Step 1 to Step 5). This suggests that:
1. Choosing the right representation of data like sparse vector representation really matters.
2. C output operations does not incur visible performance penalty as long as it is used infrequently.
3. C input operations are fast.
4. Using C++ high-level data structures does not incur visible performance penalty and they help a lot.
